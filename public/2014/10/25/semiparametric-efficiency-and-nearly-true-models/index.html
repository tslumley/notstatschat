<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.41" />


<title>Semiparametric efficiency and nearly-true models - A Hugo website</title>
<meta property="og:title" content="Semiparametric efficiency and nearly-true models - A Hugo website">



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/notstatschat_1.png"
         width="75"
         height="100"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/tslumley/notstatschat">GitHub</a></li>
    
    <li><a href="https://twitter.com/tslumley">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">4 min read</span>
    

    <h1 class="article-title">Semiparametric efficiency and nearly-true models</h1>

    
    <span class="article-date">2014/10/25</span>
    

    <div class="article-content">
      <p>Suppose you have <span class="math inline">\(N\)</span> people with some variables measured, and you choose a subset of <span class="math inline">\(n\)</span> to measure additional variables. I’m going to assume the probability <span class="math inline">\(\pi_i\)</span> that you measure the additional variables on person <span class="math inline">\(i\)</span> is <strong>known</strong>, so it has to be a setting where non-response isn’t an issue – eg, choosing which frozen blood samples to analyse, or which free-text questionnaire responses to code, or which medical records to pull for abstraction. As an example, if you have a binary outcome <span class="math inline">\(Y\)</span> you might take a case–control sample and measure <span class="math inline">\(X\)</span> on everyone with <span class="math inline">\(Y=1\)</span> and the same number of people with <span class="math inline">\(Y=0\)</span>.</p>
<p>Suppose in addition that you want to fit a particular parametric or semiparametric model <span class="math inline">\({\cal P}_{\theta,\eta}\)</span> to the data, where <span class="math inline">\(\theta\)</span> are parameters of interest and <span class="math inline">\(\eta\)</span> are nuisance parameters. For example, you might want to fit a logistic regression model where the coefficients are <span class="math inline">\(\theta\)</span> and the density of <span class="math inline">\(X\)</span> is <span class="math inline">\(\eta\)</span>.</p>
<p>There are now two possible semiparametric models for the observed data. Let <span class="math inline">\(R_i\)</span> be the indicator that person <span class="math inline">\(i\)</span> is sampled. We could have</p>
<ul>
<li>Model D: <span class="math inline">\(\pi_i=E[R_i|\textrm{variables available on everyone}]\)</span></li>
<li>Model M: the submodel of <span class="math inline">\(D\)</span> that satisfies <span class="math inline">\({\cal P}_{\theta,\eta}\)</span></li>
</ul>
<p>Typically, estimation under model M will be more efficient. For example, in the case-control setting with a logistic regression model for <span class="math inline">\(Y|X\)</span> we know that the efficient estimator under model M is unweighted logistic regression (per Prentice &amp; Pyke 1979), and that the efficient estimator under model D is weighted logistic regression with weights <span class="math inline">\(w_i=1/\pi_i\)</span>.</p>
<p>I want to consider slight misspecifications, where model M is ‘nearly true’. Gross misspecifications aren’t interesting: if the data don’t look anything like a sample from <span class="math inline">\({\cal P}_{\theta,\eta}\)</span>, a careful data analyst will notice and pick a different model. However, the difference between the efficient estimators under M and under D is <span class="math inline">\(O_p(n^{-1/2})\)</span>, so a bias of the same order is enough to outweigh the precision gain. It’s not obvious that we should expect to detect a misspecification of this size, so more precise investigation is needed.</p>
<p>The efficient estimator under <span class="math inline">\(D\)</span> is an Augmented Inverse Probability Weighted (AIPW) estimator (if you’re a biostatistician) or a calibration estimator (if you’re a survey statistician), and we can get reasonably close to it (Breslow et al, 2009). Write <span class="math inline">\(\hat\theta_{\textrm{wtd}}\)</span> for this estimator, and <span class="math inline">\(\hat\theta_{\textrm{eff}}\)</span> for the efficient estimator under <span class="math inline">\(M\)</span>.</p>
<p>Models M and D agree when there is complete data, so I will <strong>define</strong> the true value <span class="math inline">\(\theta_0\)</span> of <span class="math inline">\(\theta\)</span> as the common limit of <span class="math inline">\(\hat\theta_{eff}\)</span> and <span class="math inline">\(\hat\theta_{wtd}\)</span> with complete data. Survey statisticians call this the ‘census estimator.’ Biostatisticians call it ‘our next grant proposal’.</p>
<p>We now need a mathematical characterisation of ‘nearly true’. I will use contiguity. A sequence of distributions <span class="math inline">\(Q_n\)</span> is contiguous to a sequence <span class="math inline">\(P_n\)</span> if for every event <span class="math inline">\(A\)</span>, <span class="math inline">\(P_nA\to0\)</span> implies <span class="math inline">\(Q_nA\to 0\)</span>. They are mutually contiguous if the implication goes both ways. Let <span class="math inline">\(A\)</span> be the event that a model diagnostic accepts model <span class="math inline">\(M\)</span>, and let <span class="math inline">\(P_n\)</span> be a sequence of distributions in model M. If this is a useful diagnostic, <span class="math inline">\(P_nA\not\to 0\)</span>, so for a mutually contiguous sequence of distributions <span class="math inline">\(Q_n\)</span> in model D but not in model M, <span class="math inline">\(Q_nA\not\to 0\)</span>.</p>
<p>Now, under M <span class="math display">\[\sqrt{n}(\hat\theta_{\textrm{eff}}-\theta_0) \stackrel{d}{\to}N(0,\sigma^2)\]</span> and <span class="math display">\[\sqrt{n}(\hat\theta_{\textrm{wtd}}-\theta_0) \stackrel{d}{\to}N(0,\sigma^2+\omega^2)\]</span></p>
<p>By the Convolution Theorem, the extra variance for <span class="math inline">\(\hat\theta_{\textrm{wtd}}\)</span> under model M is pure noise, so <span class="math display">\[\sqrt{n}(\hat\theta_{\textrm{eff}}-\hat\theta_{\textrm{wtd}}) \stackrel{d}{\to} N(0,\omega^2)\]</span></p>
<p>Now, by LeCam’s Third Lemma, if we switch from <span class="math inline">\(P_n\)</span> to <span class="math inline">\(Q_n\)</span> as the data distribution there is no change in variance, but there is bias <span class="math display">\[\sqrt{n}(\hat\theta_{\textrm{eff}}-\hat\theta_{\textrm{wtd}}) \stackrel{d}{\to} N(-\kappa\rho\omega,\omega^2)\]</span> where <span class="math inline">\(\kappa\)</span> is the limit of the log likelihood ratio <span class="math inline">\(\log dQ_n/dP_n\)</span>, which governs the power of the Neyman–Pearson Lemma test, and <span class="math inline">\(\rho\)</span> measures whether the misspecification is in a direction that matters for <span class="math inline">\(\theta\)</span> or not.</p>
<p>Substituting back, under the contiguous misspecified model sequence <span class="math inline">\(Q_n\)</span>, <span class="math display">\[\sqrt{n}(\hat\theta_{\textrm{eff}}-\theta_0) \stackrel{d}{\to}N(-\kappa\rho\omega,\sigma^2)\]</span> and <span class="math display">\[\sqrt{n}(\hat\theta_{\textrm{wtd}}-\theta_0) \stackrel{d}{\to}N(0,\sigma^2+\omega^2)\]</span> So, the mean squared error of <span class="math inline">\(\hat\theta_{\textrm{wtd}}\)</span> is lower if <span class="math inline">\(\kappa^2\rho^2&gt;1\)</span>. If <span class="math inline">\(\rho\approx 1\)</span>, this happens when <span class="math inline">\(\kappa\approx 1\)</span>, at which point the most powerful test for <span class="math inline">\(Q_n\)</span> vs <span class="math inline">\(P_n\)</span> has power about 24%.</p>
<p>That is, the least-favourable misspecification of model M leads to worse mean squared error for <span class="math inline">\(\hat\theta_{\textrm{eff}}\)</span> than <span class="math inline">\(\hat\theta_{\textrm{wtd}}\)</span> before the most powerful test of misspecification is even moderately reliable, even if we (unrealistically) knew exactly the form of the misspecification.</p>
<p>Since the sense in which <span class="math inline">\(\hat\theta_{\textrm{eff}}\)</span> is optimal is precisely this local asymptotic minimax sense within <span class="math inline">\({\cal P}_{\theta,\eta}\)</span>, it seems reasonable to use the same description of optimality outside the model. Under this description of optimality, the ‘efficient’ estimator’s optimality is not robust to undetectable model misspecification.</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

