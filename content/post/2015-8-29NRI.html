---
title: 'Net Reclassification Index: surprisingly weird.'
author: "Thomas Lumley"
date:  2015-08-29
output: html_document
---



<p><em>Attention Conservation Notice: Long. Really long. No, longer than that. Here: read the <a href="http://biostats.bepress.com/uwbiostat/paper392/">original</a> instead</em>.</p>
<p>The Net Reclassification Index (NRI) is a summary of improvement in prediction when new information is added, and an intuitively plausible one. Suppose that we’re trying to predict <span class="math inline">\(Y=1\)</span> vs <span class="math inline">\(Y=0\)</span>, and that for person <span class="math inline">\(i\)</span> we have an old predicted probability <span class="math inline">\(\hat p_{\textrm{old}}(i)\)</span> and a new predicted probability <span class="math inline">\(\hat p_{\textrm{new}}(i)\)</span>.  We’d hope that the probabilities for cases (<span class="math inline">\(Y=1\)</span>) go up and the probabilities for controls (<span class="math inline">\(Y=0\)</span>) go down when more information is used.</p>
<p>Suppose the test set has <span class="math inline">\(N_1\)</span> cases and <span class="math inline">\(N_0\)</span> controls. The NRI is defined by<br />
<span class="math display">\[\frac{1}{2}\textrm{NRI}=\frac{1}{N_1}\sum_{Y_i=1} I\{\hat p_{\textrm{new}}(i)&gt;\hat p_{\textrm{old}}(i)\} - \frac{1}{N_0}\sum_{Y_i=0} I\{\hat p_{\textrm{new}}(i)&gt;\hat p_{\textrm{old}}(i)\}\]</span><br />
The definition avoids evaluating tradeoffs about how much the probabilities go up, and is standardised to be (at least apparently) comparable between data sets with different case:control ratios. </p>
<p>As any schoolchild knows, evaluating the NRI on the same data used to estimate the probabilities will make it biased upwards: you’re basically asking “Do the probabilities in these data change in the same ways as the probabilities in the data where the estimation was done?” This isn’t hard. They do. </p>
<p>Basically everyone except Margaret Pepe assumed that using an independent test dataset would make this bias go away, as it does for other measures of predictiveness, good or bad. That’s not what happens. [The <a href="http://link.springer.com/article/10.1007%2Fs12561-014-9118-0">paper by Pepe and co-workers</a> is behind a paywall, but their <a href="http://biostats.bepress.com/uwbiostat/paper392/">working paper</a> is available.]  After hearing talks about the bias I still didn’t understand why it happened. This post is an attempt to explain. My conclusion for what’s actually going on is a bit different from theirs, but the implications are similar. </p>
<p>First, looking at a silly example shows that NRI can behave badly. Suppose <span class="math inline">\(X\)</span> is also binary and is predictive of <span class="math inline">\(Y\)</span>, and that <span class="math display">\[\hat p_{\textrm{old}}=P[Y=1|X=x_i].\]</span> The prediction rule divides people into ‘high risk’ and ‘low risk’. Now define <span class="math inline">\(\hat p_{\textrm{new}}\)</span> to be larger than <span class="math inline">\(\hat p_{\textrm{old}}\)</span> for ‘high-risk’ people and to be smaller than <span class="math inline">\(\hat p_{\textrm{old}}\)</span> for ‘low-risk’ people. You can do this any way you like. </p>
<p>Since high-risk people are more likely to be cases than low-risk people, a greater proportion of cases than controls will have their probabilities go up. Conversely, a greater proportion of controls than cases will have their probabilities go down. The NRI will be positive, even though the old prediction rule is the best possible one based on <span class="math inline">\(X\)</span> and the new rule is strictly worse. </p>
<p>Since this is a silly example, it doesn’t necessarily mean there is a problem with NRI, but it isn’t encouraging. Under the same definitions of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, if we defined<br />
<span class="math display">\[\hat p_{\textrm{new}}(i)=\hat p_{\textrm{old}}(i)+\epsilon_i\]</span><br />
with <span class="math inline">\(\epsilon_i\)</span> having zero mean, independent of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, NRI would be zero. That’s still not ideal, since the predictions are worse rather than the same, but it’s certainly better than NRI being positive. </p>
<p>Can we get NRI to be positive (on average) without doing something silly? Yes, in fact. Pepe and co-workers looked at a very simple continuous case, where Normal <span class="math inline">\(X\)</span>  predicts (binary) <span class="math inline">\(Y\)</span>, and (Normal) <span class="math inline">\(Z\)</span> is independent of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.  If <span class="math inline">\(\hat p_{\textrm{old}}\)</span> is based on logistic regression with <span class="math inline">\(X\)</span>, and <span class="math inline">\(\hat p_{\textrm{new}}\)</span> on logistic regression with <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>, their simulations showed the NRI will be positive (on average) even though the predictions are slightly worse using <span class="math inline">\(Z\)</span>. I’ve put an <a href="https://gist.github.com/tslumley/77d3653b5a43fc129d15">example up as a GitHub gist.</a></p>
<p>The simulation shows that NRI is weird, but it still doesn’t explain why.  When confusing things happen with logistic regression, a useful trick is to try the same problem with linear regression. Either the same confusing things will happen, but will be easier to analyse, or they won’t happen, meaning that the non-linearity is important. </p>
<p>In a <a href="https://gist.github.com/tslumley/6d3aeb0a8148c0f03028">linear version</a> of the simple problem with Normal predictors, the NRI averages very close to zero. That’s still probably not right – it should be negative – but it is different from logistic regression. Non-linearity is important.</p>
<p>Because logistic regression is an exponential-family model, the maximum likelihood estimators are moment estimators. We have <span class="math inline">\(E[\hat p_{\textrm{old}}-\hat p_{\textrm{new}}]\approx 0\)</span> both overall and conditional on <span class="math inline">\(X\)</span>. Since <span class="math inline">\(\textrm{logit} \hat p_{\textrm{new}}-\textrm{logit} \hat p_{\textrm{old}}\)</span> has a symmetric distribution, <span class="math inline">\(\hat p_{\textrm{new}}-\hat p_{\textrm{old}}\)</span> will have an asymmetric, skewed distribution. Specifically, it will be positively skewed when <span class="math inline">\(p\)</span> is small, symmetric when <span class="math inline">\(p\approx 0.5\)</span>, and negatively skewed when <span class="math inline">\(p\)</span> is large; that’s the only way to force it into <span class="math inline">\([0,\,1]\)</span>. </p>
<p>A positively-skewed, mean-zero distribution (typically) has a negative median, and a negatively-skewed mean-zero distribution (typically) has a positive median; the ‘typical’ behaviour holds for these logit-Normal distributions. The change in <span class="math inline">\(\hat p\)</span> will be positively skewed and have negative median when <span class="math inline">\(\hat p\)</span> is small; it will be negatively skewed and have positive median when <span class="math inline">\(\hat p\)</span> is large. Since <span class="math inline">\(X\)</span> is predictive, <span class="math inline">\(\hat p\)</span> is larger for cases than for controls, so <span class="math inline">\(P[\hat p_{\textrm{new}}&gt;\hat p_{\textrm{old}}]\)</span> is greater than 1/2 for cases and less than 1/2 for controls and the NRI will be positive on average.</p>
<p>The silly example shows that NRI can behave very badly for arbitrary prediction rules. For rules that are well calibrated in the sense of means, the non-linearity of the data-to-probability transformation and the use of ordering rather than differences in NRI makes it tend positive when useless variables are added. Even with a linear model, though, the NRI doesn’t pick up the degradation of performance from irrelevant variables.</p>
<p>[<strong>tl;dr:</strong>  NRI? Just say “No, thank you.”]</p>
