---
title: Does svyglm use robust standard errors?
author: Thomas
date: '2025-12-01'
slug: does-svyglm-use-robust-standard-errors
categories: []
tags: []
---



<div id="yes" class="section level1">
<h1>Yes</h1>
<p>This question comes up from time to time on social media or StackExchange or email, often from reasonable people, so extra emphasis might be useful.</p>
<p>There are two parts to the answer:</p>
<div id="yes-1" class="section level2">
<h2>Yes</h2>
<p>and</p>
</div>
<div id="if-you-think-about-it-what-else-could-it-be-using" class="section level2">
<h2>If you think about it, what <em>else</em> could it be using?</h2>
<p>Write <span class="math inline">\(\hat\beta\)</span> for the <code>svyglm</code> estimator. Theory says the estimator solves the weighted score equations</p>
<p><span class="math display">\[U(\beta)=\sum_{i=1}^N \frac{R_i}{\pi_i} U_i(\beta)=0\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the population size, <span class="math inline">\(R_i\)</span> is the sampling indicator, and <span class="math inline">\(U_i=\partial_\beta \ell_i(\beta)\)</span> is the score. Doing an Taylor series expansion on this gives</p>
<p><span class="math display">\[U(\beta) = U(\hat\beta)+(\hat\beta-\beta)\frac{\partial U}{\partial\beta}+\text{remainder}\]</span>
so that
<span class="math display">\[\hat\beta-\beta\approx \left [\frac{\partial U}{\partial\beta}\right]^{-1} U(\beta_0).\]</span>
The large-sample variance approximation is then the ‘sandwich’
<span class="math display">\[\widehat{\text{var}}[\hat\beta]= \left [\frac{\partial U}{\partial\beta}\right]^{-1} \widehat{\text{var}}[U(\beta_0)] \left [\frac{\partial U}{\partial\beta}\right]^{-1}.\]</span></p>
<p>This is all similar to, eg, Huber or White’s derivation of the sandwich estimator. The only difference is that the middle term<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> has to be estimated differently because of the survey design. That is, the <code>svyglm</code> variance estimator <em>generalises</em> the familiar sandwich estimators to allow for non-trivial sampling.</p>
<p>The middle term is the variance of an estimated population total, and is estimated the same way as for any other population total. This is <strong>literally</strong> true: all the population-total variance estimates go through the function <code>svyrecvar</code>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>The middle term is
<span class="math display">\[\sum_{i,j} \frac{R_{ij}}{\pi_{ij}}\frac{R_iU_i}{\pi_i}\frac{R_jU_j}{\pi_j}\]</span>
where <span class="math inline">\(\pi_{ij}\)</span> are the pairwise sampling probabilities. If you had independent sampling of individual records, so <span class="math inline">\(\text{cov}[R_i,R_j]=0\)</span>, the middle term would reduce to
<span class="math display">\[\sum_{i} \frac{R_{i}}{\pi_{i}}\left[\frac{R_iU_i}{\pi_i}\right]^{\otimes 2}\]</span>
and the whole thing simplifies to a standard sandwich estimator.</p>
<p>Model-based standard error estimates are based on simplifying the sandwich estimator by making stronger assumptions about the structure of the middle term. We can’t do this with survey data: we don’t necessarily assume anything about how the finite population was generated, so no simplifications are available.</p>
<p>So, <strong>yes</strong>, all the model in the <code>survey</code> and <code>svyVGAM</code> packages use model-robust standard errors.</p>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>meat? cheese? falafel? avocado?<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>or analogous functions such as <code>ppsvar</code> or <code>twophasevar</code> for other categories of design<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
