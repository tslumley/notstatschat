---
title: Generalisability, prediction, and causation
author: ''
date: '2021-05-02'
slug: generalisability-prediction-and-causation
categories: []
tags: []
---



<p>One of the big steps forward in statistics over the past few decades is the widespread appreciation that regression modelling for causal inference and predictive inference are different<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. In causal inference you choose your model so that one of the coefficients means what you want it to mean; in predictive inference you choose your model so that it predicts well, and you don’t care about the interpretations of the coefficients. A relationship can provide reliable prediction without being causal. For example, in the US, insurance companies sent me letters saying I could save money on car insurance by switching to them<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. I called one of them and was told the letters were because I had a good credit score and this predicted low insurance risk. A good credit score obviously does not <em>cause</em> low driving risk or low risk of theft, but that’s not a problem if you’re just using it to select potential victims.</p>
<p>This actually isn’t a good example, because the association between credit score and insurance risk probably is causal, and it wouldn’t be useful to the insurance companies if it wasn’t. It’s not <em>directly</em> causal – it’s confounded by age and income and where you live and general level of risk aversion – but the association exists <em>for reasons</em>. If you drew an appropriate causal DAG and worked out the implied conditional independence relations, you would (I argue) find that the causal DAG says credit score would be associated with insurance risk conditional on other variables the insurance companies are able to measure on non-customers. And if you asked how someone originally came up with the idea, there’s a good chance the motivation would have been an informal version of this causal argument rather than a chance observation of a correlation.</p>
<p>Causality is not important to prediction when the training set is a simple random sample of the data the model will be used on in production. In that case, the associations are whatever they are, and you can just estimate them. It’s pretty common, though, for a model to be used in prediction for <em>new</em> data not available at the time it was fitted – either data measured at a later time or data from different target populations. Prediction requires at least some limited sort of generalisability, so if you’re interested in prediction you should be interested in reasons for generalisability. The second-best reason for generalisability (after genuine probability sampling) is that the associations are the result of some causally stable relationships. You don’t necessarily need to know <a href="https://theconversation.com/red-sky-at-night-shepherds-delight-the-science-of-beautiful-sunsets-99598">why</a> <em>red sky at night is shepherd’s delight</em> in order to use the relationship<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>, but you should care that there <em>are</em> reasons.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>there’s also purely descriptive regression modelling, and there’s a nice paper <del>I can’t find right now</del> on <a href="https://jstor.org/stable/2984458">regression for process control</a>, <del>I think</del> by Lindley (thanks, Guilherme Jacob)<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>even though I didn’t have a car or a drivers licence<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>though knowing might stop you trying to use the rule in the tropics<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
