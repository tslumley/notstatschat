---
title: Crossed clustering and parallel invention
author: Thomas Lumley
date: '2021-09-18'
slug: crossed-clustering-and-parallel-invention
categories: []
tags: []
---



<p>This week, I was prompted to find some old R code</p>
<pre><code>xeffect.glm&lt;-function(glm.obj,g1,g2){
    if (!exists(&quot;rowsum&quot;)) require(survival4)
    umat&lt;-estfun.glm(glm.obj)
    usum1&lt;-rowsum(umat,g1,reorder=F)
    usum2&lt;-rowsum(umat,g2,reorder=F)
    g1a&lt;-as.numeric(as.factor(g1))
    g2a&lt;-as.numeric(as.factor(g2))
    g12&lt;-g1a*(1+max(g2a))+g2a
    usum12&lt;-rowsum(umat,g12,reorder=F)
    utu&lt;-(t(usum1)%*%usum1)+t(usum2)%*%usum2-t(usum12)%*%usum12
    modelv&lt;-summary(glm.obj)$cov.unscaled
    modelv%*%utu%*%modelv
}</code></pre>
<p>You can tell it’s old: the use of <code>F</code> rather than <code>FALSE</code> indicates I was still using S-PLUS reasonably often, and it was a time when <code>rowsum</code> wasn’t in base R (or was only recently). I could find the code because it’s been sitting on my old UW web page, which they kindly haven’t taken down yet. The tarball files are dated August 1998; I’m fairly sure some of the code even pre-dates CRAN.</p>
<p>The code computes standard error estimates for a generalised linear model with clustering on two crossed factors. This sort of data was the original (1996) idea for my PhD, and I did cover standard error estimation for this problem there, though not the more-general problem of GEE-type estimation that I had originally planned; I was diverted to space and time correlation.</p>
<p>The variance estimation idea is fairly easy. The way I’d phrase it now is that you want to find the variance of <span class="math inline">\(\hat\beta\)</span> so you represent <span class="math inline">\(\hat\beta\)</span> in terms of its influence functions
<span class="math display">\[\sqrt{n}(\hat\beta-\beta_0)=\frac{1}{n}\sum_{i=1}^n h_i(\beta_0)+o_p(1).\]</span>
Now,
<span class="math display">\[n\mathrm{var}[\hat\beta] \approx \sum_{i,j} \mathrm{cov}[h_i(\beta_0),h_j(\beta_0)]\]</span>
and
<span class="math display">\[\widehat{\mathrm{var}}[\hat\beta]=\frac{1}{n}\sum_{i,j\textrm{ correlated}} h_i(\hat\beta)h^T_j(\hat\beta)\]</span>
Back then, I thought in terms of sandwich estimators, where <span class="math inline">\(h_i=I^{-1}U_i\)</span> with <span class="math inline">\(U_i\)</span> the estimating function and <span class="math inline">\(I\)</span> the derivative matrix that would be the Fisher information if this was maximum likelihood. The middle of the sandwich is
<span class="math display">\[\hat J=\frac{1}{n}\sum_{i,j\textrm{ correlated}} U_i(\hat\beta)U^T_j(\hat\beta)\]</span></p>
<p>You need the restriction in the sum to <span class="math inline">\((i,j)\)</span> correlated. If you sum over all pairs <span class="math inline">\((i,j)\)</span>, the estimator collapses to <span class="math inline">\((\sum_i U_i(\hat\beta))^{\otimes 2}\)</span>, which is identically zero. Even if you could evaluate at <span class="math inline">\(\beta=\beta_0\)</span> instead of <span class="math inline">\(\beta=\hat\beta\)</span> it wouldn’t work: you’d get an unbiased estimator, but not a consistent one. Basically, you need the sum to be over <span class="math inline">\(o(n^2)\)</span> terms – or, to get some leverage for proofs, <span class="math inline">\(O(n^{2-\delta})\)</span> terms. In terms of clustering, you need the number of clusters to go to infinity, though the cluster size can also grow. The proof is by Chebyshev’s inequality and just counting things, together with (as always in Statistics) a second-order Taylor series expansion. In practice, as the asymptotics suggests, you need the number of terms in the sum to be a fairly small fraction of the <span class="math inline">\(n^2\)</span> possible terms. You don’t need the correlation to be generated by crossed random effects, which was important to me at the time though in fact most examples of this sort of sparse correlation do come from crossed random effects.</p>
<p>When you do have crossed sets of clustering, there’s an interesting choice to make. Suppose (as in the S code) you have clustering on <span class="math inline">\(g_1\)</span> and on <span class="math inline">\(g_2\)</span>. An easy computational approach (avoiding quadratic time or space computations) is to compute variance matrices <span class="math inline">\(V_1\)</span> clustering on <span class="math inline">\(g_1\)</span>, <span class="math inline">\(V_2\)</span> clustering on <span class="math inline">\(g_2\)</span>, and <span class="math inline">\(V_{12}\)</span> clustering on the combinations of <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span>. The variance estimator <span class="math inline">\(V_1+V_2-V_{12}\)</span> is unbiased (well, would be unbiased if computed at <span class="math inline">\(\beta_0\)</span>), but it is not necessarily positive definite. The estimator <span class="math inline">\(V_1+V_2\)</span> is biased upwards but is necessarily positive definite. The bias is small if the crossed factors are nearly orthogonal, but if they’re correlated – eg, primary school district and secondary school district –the bias can be quite big. The bias would approach a factor of 2 if <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span> were nearly identical. The code above uses the unbiased estimator, but there’s some argument that the biased estimator would typically be better since sandwich estimators tend to underestimate in practice.</p>
<p>Apart from being in my thesis in 1998, this approach led to a few papers by me and other Seattle people: one with <a href="https://www.jstor.org/stable/3068352">Nicole Mayer-Hamblett and Steve Self</a>, a <a href="https://pubmed.ncbi.nlm.nih.gov/15208201/">couple</a> <a href="https://pubmed.ncbi.nlm.nih.gov/17121864/">by</a> Patrick Heagerty and Diana Miglioretti, one by Patrick <a href="https://www.jstor.org/stable/25791691">with some political science researchers</a>. Patrick has used the biased but guaranteed-positive version of the estimator.</p>
<p>I looked for the code because someone had been trying to do this sort of variance estimation with the <code>survey</code> package – that’s not going to work, because multistage sampling is about nested rather than crossed effects. There’s apparently code for Stata to do this sort of thing, and a nice paper in the <a href="https://www.jstor.org/stable/25800796"><em>Journal of Business and Economic Statistics</em></a> inventing the idea and applying it to economics examples. They use the unbiased version of the estimator. I wouldn’t be very surprised if other groups of people had also independently come up with the same idea – it’s a straightforward-enough extension of the basic Huber/White/Domowitz sandwich estimators. I’m not even arguing that it would be better if people didn’t reinvent statistical ideas; at some point it’s easier just to solve a problem than to think how someone else in another field might have described their idea for solving an analogous problem. We probably could use a few more generalists in academic statistics, but that’s a balance that’s not so easy to get right.</p>
<p>Some form of this will probably be in the next version of the <code>survey</code> package, but I need to decide how general and with what user interface.</p>
