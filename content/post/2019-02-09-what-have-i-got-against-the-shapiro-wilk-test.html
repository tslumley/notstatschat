---
title: What have I got against the Shapiro-Wilk test?
author: Thomas Lumley
date: '2019-02-09'
slug: what-have-i-got-against-the-shapiro-wilk-test
categories: []
tags: []
---



<p>The Shapiro-Wilk test is a test of the null hypothesis that data come from a Normal distribution, with power against a wide range of alternatives. So what do I have against it?</p>
<p>Well, to start with, it’s a test of the null hypothesis that data come from a Normal distribution, with power against a wide range of alternatives.</p>
<p>There are two reasons you might want a test of the hypothesis that data come from a particular distribution <span class="math inline">\(P\)</span> or a particular set of distributions (ie, model) <span class="math inline">\({\cal P}_\theta\)</span>. First, that might actually be the question you’re interested in. Second, it might be an important step in deciding what analysis you are going to do to answer the question you’re actually interested in. The reason these are unusual for the Normal distribution is the Central Limit Theorem.</p>
<p>The Central Limit Theorem says that a lot of processes tend to produce Normal distributions (or maybe log-normal). Having (approximately) a Normal distribution for the unexplained variation is not distinctive; it doesn’t provide a good test of a theory. I don’t think I’ve ever seen an example where a scientist wanted to test whether data had a Normal distribution because theory implied that it should. [Update: ok, <a href="https://notstatschat.rbind.io/2018/08/01/testing-probability-distribution-generators/">testing random number generators</a> is an arguable exception]</p>
<p>That’s in contrast to power-law distributions, for example. There are mathematical models that imply power-law distributions for, say, earthquake sizes, or number of links to a web page. The fact that these data are a terrible fit<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> to a power-law distribution is<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> of scientific interest: a scientific theory is being subjected to a severe test, and failing. People have done this for albatross flight durations – proposing the distribution<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>, rejecting it<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>, and then arguing it fits if you model it right<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>.</p>
<p>Similarly, there are situations where scientific theory says a set of points should be be a fairly good fit to a Poisson process, and people test the fit because of that theory. And the genome-wide association literature is full of people looking at fit to a uniform distribution for <span class="math inline">\(p\)</span>-values – well, to an exponential distribution for log <span class="math inline">\(p\)</span>-values, typically – to pick up population substructure or modelling failures, though not usually with a formal test, an issue I’ll get to later.</p>
<p>The reason people test for fit to the Normal distribution is… well, to be honest, it’s typically because they read a statistics textbook written by a statistician who should have known better. Given how old some statistics textbooks are, the statistician probably does know better now.</p>
<p>If you want <span class="math inline">\(\bar X\)</span> to have a Normal distribution, and the <span class="math inline">\(X\)</span>s are independent, it is necessary and sufficient that the <span class="math inline">\(X\)</span>s are Normal<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. If you just want <span class="math inline">\(\bar X\)</span> to have approximately a Normal distribution – as you do – it is sufficient, but far from necessary.</p>
<p>If the sample size is large enough, <span class="math inline">\(\bar X\)</span> will always have approximately a Normal distribution. In small-enough samples your test will not have useful power; in large-enough samples you don’t need <span class="math inline">\(X\)</span> to be Normal; there’s potentially a middle ground. “Large enough” depends on the distribution of <span class="math inline">\(X\)</span>, and primarily on outliers in <span class="math inline">\(X\)</span>: if the <span class="math inline">\(X\)</span>s all have the same distribution, it’s primarily the skewness and kurtosis of <span class="math inline">\(X\)</span>. So if that’s why you’re doing a Normality test you should want a test that pays most attention to the skewness and kurtosis. There are tests like that; you have to worry about how to weight the two moments, and so on, and they look a bit <em>ad hoc</em>, but that’s basically Latin for “actually relevant to the question we’re talking about”, so I’m ok with it.</p>
<p>According to Patrick Royston<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>, who knows a lot about the Shapiro-Wilk test,</p>
<blockquote>
<p>Its power characteristics are well known and may be summarized by saying that it is strongest against short-tailed (platykurtic) and skew distributions and weakest against symmetric moderately long- tailed (leptokurtic) distributions.</p>
</blockquote>
<p>That’s not what we’re looking for as a pre-test before analysing means. It’s powerful against too many alternatives, including some we don’t care about, so it has to have lost power against the alternatives we do care about.</p>
<p>On top of that, the Shapiro-Wilk test is an example of an approach I don’t like. One reasonably good way of looking at distributional fit is to draw a quantile-quantile plot. The plot is easy to draw (we have to do a bit of thinning for large data sets) and reasonably easy to interpret. The basic shape of the plot isn’t sensitive to the sample size. Shapiro and Wilk said</p>
<blockquote>
<p>This study was initiated, in part, in an attempt to summarize formally certain indications of probability plots. In particular, could one condense departures from statistical linearity of probability plots into one or a few ‘degrees of freedom’ in the manner of the application of analysis of variance in regression analysis</p>
</blockquote>
<p>One obviously could: Shapiro and Wilk’s <span class="math inline">\(W\)</span> statistic (proportional to) the slope of a linear regression of <span class="math inline">\(X\)</span> on the qq-plot (after scaling <span class="math inline">\(X\)</span> to unit variance). The maximum possible value of <span class="math inline">\(W\)</span> is 1. If the <span class="math inline">\(X\)</span>s are all from the same Normal distribution, <span class="math inline">\(W\)</span> converges to 1 as the sample size increases, and if they aren’t it converges to some number less than 1. The actual sampling distribution of <span class="math inline">\(W\)</span>, however, is ridiculously complicated. Well, Shapiro and Wilk derived it for <span class="math inline">\(n=3\)</span>, but it quickly becomes complicated. The paper by Patrick Royston that I mentioned? It empirically fits a three-parameter log-normal distribution to <span class="math inline">\(\log(1-W)\)</span> for <span class="math inline">\(4\leq n\leq 11\)</span> and a two-parameter log-normal to <span class="math inline">\(1-W\)</span> for <span class="math inline">\(12\leq n\leq 2000\)</span>. Those formulas are what R uses.</p>
<p>You might incautiously think the bootstrap would be helpful. It isn’t. Because the null hypothesis is at the edge of the possible range, there’s no reason to believe the bootstrap would give the right sampling distribution for <span class="math inline">\(W\)</span>. What it does work for, however, is to make the test even less necessary, since you could just use the bootstrap on whatever analysis you were doing and relax a little about assumptions.</p>
<p>There is a solution, of course. The test is location and scale invariant, so if we were inventing the test now we could save a lot of effort by just computing <span class="math inline">\(W\)</span> on a few thousand samples of size <span class="math inline">\(n\)</span> from <span class="math inline">\(N(0,1)\)</span> whenever you wanted to use it. So in that sense the baroquely complicated mathematical analysis isn’t a problem any more.</p>
<p>We haven’t got to the biggest problem, though. I said you might want to test because <em>it might be an important step in deciding what analysis you are going to do</em>. If it is, you’re now doing a different analysis. Instead of doing a t-test on <span class="math inline">\(X\)</span> you’re randomly (ie, based on the data) deciding to do either a <span class="math inline">\(t\)</span>-test on <span class="math inline">\(X\)</span> or on <span class="math inline">\(\log X\)</span>. Or worse, randomly (ie, based on the data) deciding to do either a <span class="math inline">\(t\)</span>-test on <span class="math inline">\(X\)</span> or a Wilcoxon test on <span class="math inline">\(X\)</span>. You now need to worry about the operating characteristics of that whole combined procedure. Your <span class="math inline">\(t\)</span>-test <span class="math inline">\(p\)</span>-value and confidence interval aren’t right any more; you need a maybe-$t-test-maybe-not <span class="math inline">\(p\)</span>-value and confidence interval. These could be similar or they could be very different. In this particular case, Murphy is not on your side and they are noticeably different<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>.</p>
<blockquote>
<p>Preliminary testing for normality seriously altered the conditional Type I error rates of the subsequent main analysis for both parametric and nonparametric tests.</p>
</blockquote>
<p>Finally, I talked about testing for Normality perhaps being useful in a Goldilocks middle ground of sample sizes. Actually, it’s not at all clear the middle ground exists, and the test may well go from too cold to too hot without any ‘just right’.</p>
<p>So, overall. You usually don’t want to test for fit to a Normal distribution. If you do, you usually don’t care primarily about the alternatives to which the Shapiro-Wilk test is popular. Unless the conclusion is very clear, pre-testing is going to completely munt your subsequent tests. And if the conclusion is clear then you can look at the qq-plot; you don’t need to get maths to look at it for you, and you might learn something else about the data.</p>
<p>Check out my <del>SoundCloud</del> <a href="https://www.ncbi.nlm.nih.gov/pubmed/11910059">paper that you can cite if you need a reference about not-testing being ok</a></p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://arxiv.org/abs/0706.1062" class="uri">https://arxiv.org/abs/0706.1062</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>or should be<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="https://www.nature.com/articles/381413a0" class="uri">https://www.nature.com/articles/381413a0</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/17960243" class="uri">https://www.ncbi.nlm.nih.gov/pubmed/17960243</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p><a href="https://arxiv.org/abs/0802.1762" class="uri">https://arxiv.org/abs/0802.1762</a><a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Yes, <strong>necessary</strong>. The <a href="https://www.encyclopediaofmath.org/index.php/L%C3%A9vy-Cram%C3%A9r_theorem">Lévy-Cramér Theorem</a>. I learned this from Pollard’s <em>Users’ Guide to Measure-Theoretic Probability</em><a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Royston, Patrick (September 1992). “Approximating the Shapiro–Wilk W-test for non-normality”. Statistics and Computing. 2 (3): 117–119. <a href="doi:10.1007/BF01891203" class="uri">doi:10.1007/BF01891203</a><a href="#fnref7">↩</a></p></li>
<li id="fn8"><p><a href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-12-81" class="uri">https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-12-81</a><a href="#fnref8">↩</a></p></li>
</ol>
</div>
