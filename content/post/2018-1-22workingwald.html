---
title: "More tests for survey data"
author: "Thomas Lumley"
date:  2018-01-22
output: html_document
---



<p>If you know about design-based analysis of survey data, you probably know about the Rao-Scott tests, at least in contingency tables.  The tests started off in the 1980s as “ok, people are going to keep doing Pearson <span class="math inline">\(X^2\)</span> tests on estimated population tables, can we work out how to get <span class="math inline">\(p\)</span>-values that aren’t ludicrous?” Subsequently, they turned out to have better operating characteristics than the Wald-type tests that were the obvious thing to do – mostly by accident.  Finally, they’ve been adapted to regression models in general, and reinterpreted as tests in a marginal working model of independent sampling, where they are distinctive in that they weight different directions of departure from the null in a way that doesn’t depend on the sampling design. </p>
<p>The Rao–Scott test statistics are asymptotically equivalent to <span class="math inline">\((\hat\beta-\beta_0)^TV_0^{-1}(\hat\beta-\beta_0)\)</span>, where <span class="math inline">\(\hat\beta\)</span> is the estimate of <span class="math inline">\(\beta_0\)</span>, and <span class="math inline">\(V_0\)</span> is the variance matrix you’d get with full population data. The standard Wald tests are targetting  <span class="math inline">\((\hat\beta-\beta_0)^TV^{-1}(\hat\beta-\beta_0)\)</span>, where <span class="math inline">\(V\)</span> is the actual variance matrix of <span class="math inline">\(\hat\beta\)</span>.  One reason the Rao–Scott score and likelihood ratio tests work better in small samples is just that score and likelihood ratio tests seem to work better in small samples than Wald tests. But there’s another reason. </p>
<p>The actual Wald-type test statistic (up to degree-of-freedom adjustments) is <span class="math inline">\((\hat\beta-\beta_0)^T\hat V^{-1}(\hat\beta-\beta_0)\)</span>. In small samples <span class="math inline">\(\hat V\)</span> is often poorly estimated, and in particular its condition number is, on average, larger than the condition number of <span class="math inline">\(V\)</span>, so its inverse is wobblier. The Rao–Scott tests obviously can’t avoid this problem completely: <span class="math inline">\(\hat V\)</span> must be involved somewhere. However, they use <span class="math inline">\(\hat V\)</span> via the eigenvalues of <span class="math inline">\(\hat V_0^{-1}\hat V\)</span>; in the original Satterthwaite approximation, the mean and variance of these eigenvalues.  In the typical survey settings, <span class="math inline">\(V_0\)</span> is fairly well estimated, so inverting it isn’t a problem. The fact that <span class="math inline">\(\hat V\)</span> is more ill-conditioned than <span class="math inline">\(V\)</span> translates as fewer degrees of freedom for the Satterthwaite approximation, and so to a more conservative test.  This conservative bias happens to cancel out a lot of the anticonservative bias and the tests work relatively well.  </p>
<p>Here’s an example of qqplots of <span class="math inline">\(-\log_{10} p\)</span>-values simulated  in a Cox model: the Wald test is the top panel and the Rao–Scott LRT is the bottom panel. The clusters are of size 100; the orange tests use the design degrees of freedom minus the number of parameters as the denominator degrees of freedom in an <span class="math inline">\(F\)</span> test. </p>
<div class="figure">
<img src="https://78.media.tumblr.com/f9970ca528f7ed8067b48b9f781f8ab6/tumblr_inline_p2zaz9LnDD1s1hdxy_540.png" />

</div>
<p>So, what’s new? SUDAAN has tests they call “Satterthwaite Adjusted Wald Tests”, which are based on <span class="math inline">\((\hat\beta-\beta_0)^T\hat V_0^{-1} (\hat\beta-\beta_0)\)</span>.  I’ve added similar tests to version 3.33 of the survey package (which I hope will be on CRAN soon).  These new tests are (I think) asymptotically locally equivalent to the Rao–Scott LRT and score tests. I’d expect them to be slightly inferior in operating characteristics just based on traditional folklore about score and likelihood ratio tests being better. But you can do the simulations yourself and find out. </p>
<p>The implementation is in the <code>regTermTest()</code> function, and I’m calling these “working Wald tests” rather than “Satterthwaite adjusted”, because the important difference is the substitution of <span class="math inline">\(V_0\)</span> for <span class="math inline">\(V\)</span>, and because I don’t even use the Satterthwaite approximation to the asymptotic distribution by default. </p>
