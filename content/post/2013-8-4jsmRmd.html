---
title: "Some failure modes of statistics research talks"
author: "Thomas Lumley"
date: 2013-08-04
output: html_document
---



<p>Written before #JSM2013 actually starts, so it’s not about your talk there.</p>
<p>Also, this is about deliberate choices by the presenter, and specifically about statistics research talks. </p>
<ol style="list-style-type: decimal">
<li><p><em>“The Overgeneralized Beta Distribution”</em>. There is a place for new parametric distributions, but it’s a fairly small place and mostly occupied by distributions derived from underlying substantive knowledge.</p></li>
<li><p><em>“Asymptotics of an uninteresting estimator”</em>. If there were a novel mathematical idea this would be fine, but otherwise we know its asymptotic behavior and roughly why it happens, and we can’t read your notation fast enough anyway.</p></li>
<li><p><em>“A simple mathematical solution to a complex non-mathematical problem”</em> Includes, but is not limited to, straw-man Bayesian/Frequentist talks.</p></li>
<li><p><em>“Small improvements from heroic assumptions”</em>. Yes, you can do second-order Cornish-Fisher expansions, but do you believe the distributional assumptions hold <em>that</em> accurately?</p></li>
<li><p><em>“My model takes five pages!”</em> Predominantly, but not exclusively, a Bayesian problem.  If you’re solving a real problem don’t fill all your slides with model and proposal distributions. If you’re not? Eh.</p></li>
<li><p><em>“Implausible results from inadequate data.”</em> You battled strong confounding, non-classical measurement error, and 90% missing data, and used clever statistical techniques to demonstrate that the conventional wisdom on health and exercise was completely wrong.</p></li>
<li><p><em>“Uninteresting results from inadequate data”</em> You battled strong confounding, non-classical measurement error, and 90% missing data, and and used clever statistical techniques to demonstrate that the conventional wisdom on health and exercise was completely correct.</p></li>
<li><p><em>“I did an analysis.”</em> That’s good for your clients or collaborators, but unless it helps us do one, this isn’t the right venue. </p></li>
<li><p><em>“Mine is faster than yours”</em> Useful if it’s true and the problem is computation-constrained, but it’s not, and it’s not.</p></li>
<li><p><em>“Small-sample efficiency comparisons”</em> These can’t be comprehensive, so they are only useful when the scope of the real question is very narrow. Is there a reason you know the treatment has exactly the same effect on everyone?</p></li>
<li><p><em>“You need little teeny eyes for reading little teeny print”</em> And I left my opera glasses behind.</p></li>
<li><p><em>“It worked for Dr Ishihara”</em> He was actually <em>trying</em> to make his slides into vision test.</p></li>
</ol>
<p><em>“I did an analysis”</em> is the least annoying of these, since the background is often interesting and the analysis sensible. It’s also one of the few that would be a good talk in the right setting.</p>
<p>My own contribution to #3 is <a href="http://faculty.washington.edu/tlumley/multilevel.pdf">here</a>, but in partial defense (a) it was on a web page, not at a conference, (b) I was a student, and (c) it’s less over-the-top and less incorrect than typical for the genre.</p>
<p>It’s possible that my JSM poster will be a #9 failure, but I think it’s a setting where users actually are computationally constrained and there isn’t an easier way.  </p>
