---
title: What are packages for?
author: Thomas Lumley
date: '2018-12-17'
slug: what-are-packages-for
categories: []
tags: []
---



<div class="figure">
<img src="/post/2018-12-17-what-are-packages-for_files/packages.png" style="width:60.0%" />

</div>
<p>It’s an interesting question, but the implication of <em>wasted</em> depends not just on the actual statistics about package survival (which we’ll get to), but on why people write packages. And, I suppose, on why they <em>should</em> write packages.</p>
<p>One reason people write packages is to improve other people’s data analysis, certainly. But it’s not the only reason, nor should it be. People write packages to provide reference implementations of new statistical methods. We write packages to try out and discuss programming ideas. We write packages to learn about writing code. And we write packages for fun. The first aim depends on medium-term stability, and to some extent the second does as well. The others don’t necessarily.</p>
<p>The last two reasons are fairly self-explanatory. As an example of packages as discussion/research, consider all the work done by Duncan Temple Lang on embedding R in everything and everything in R, back at the start of the century. You can’t even <strong>find</strong> most of the source code, let alone <strong>run</strong> it. Even at the time, getting it to run on many systems was a bit tricky, but Duncan’s work informed the discussion on embedding and interfaces for years. The packages might have been more useful if they had been maintained in the long term, but it’s not clear – what is clear is that it would have taken a lot of (potentially wasted) effort to do so.</p>
<p>An example that falls across multiple categories is Hadley Wickham’s sequence of packages <code>reshape</code>, <code>reshape2</code>, <code>plyr</code>, and <code>dplyr</code> for data restructuring. These were intended to be useful and used right from the start, but they also represent a development of ideas on tidy data and on the right abstractions for manipulating it.</p>
<p>My package <code>bigQF</code> explores efficient ways of evaluating tail probabilities for quadratic forms. I don’t expect it to stop working, but its main purpose in life is to have components extracted and repurposed inside other packages for rare-variant genetic epidemiology. It’s aimed at developers, not at users.</p>
<p>My <code>svylme</code> for mixed models on survey data has a less clear future. It’s experimental: the best algorithms, estimators, and user interface are all unclear at the moment. The code will continue to be developed and supported, but it may well end up inside the <code>survey</code> package, in which case the <code>svylme</code> package will be left to wither away on its own.</p>
<p>One of the problems caused by having all these reasons is that it’s less obvious to the user which category a package is in. But we can at least consider the thousands of CRAN packages as having some sort of intended commitment to long-term existence. It’s not hard to get a package on CRAN, but CRAN runs daily package checks, and packages that stop working get removed fairly rapidly.</p>
<div id="how-long-then-do-cran-packages-last" class="section level3">
<h3>How long, then, do CRAN packages last?</h3>
<p>First, we need all the packages</p>
<pre class="r"><code>library(dplyr)
library(httr)
library(xml2)</code></pre>
<p>These are currently available</p>
<pre class="r"><code>cran&lt;-available.packages()</code></pre>
<p>And these are all the packages that have been taken off CRAN, either to make way for a new version, or because they broke or were orphaned.</p>
<pre class="r"><code>archived&lt;-GET(&quot;https://cran.r-project.org/src/contrib/Archive/&quot;)</code></pre>
<p>This code extracts the package names from the HTML</p>
<pre class="r"><code>archived_pkg&lt;-xml_find_all(content(archived), &quot;//body/table/tr/td/a&quot;)
archived_list&lt;-as_list(archived_pkg)[-1]
length(archived_list)</code></pre>
<pre><code>## [1] 12037</code></pre>
<pre class="r"><code>archived_names&lt;-sapply(archived_list, function(x) sub(&quot;/&quot;,&quot;&quot;,x[[1]][[1]]))
archived_names&lt;-setdiff(archived_names, &quot;README&quot;)</code></pre>
<p>So, first: how many packages ever on CRAN have been dropped</p>
<pre class="r"><code>cran_names&lt;-rownames(cran)
length(setdiff(archived_names,cran_names))</code></pre>
<pre><code>## [1] 2009</code></pre>
<p>Out of how many?</p>
<pre class="r"><code>length(union(archived_names, cran_names))</code></pre>
<pre><code>## [1] 15372</code></pre>
<p>Not a very high fraction.</p>
<p>As statisticians, we’d like a survival analysis. This means getting all the archive dates. I’m going to use the Auckland CRAN archive because it’s close. Yes, it’s a <code>for</code> loop. That’s because when a long-running <code>for</code> loop breaks in the middle I can easily see where it got up to and whether it got the earlier entries right.</p>
<pre class="r"><code>all_archives&lt;-vector(&quot;list&quot;,length(archived_names))
for(i in seq_len(length(archived_names))){
  pkg&lt;-archived_names[i]
  all_archives[[i]]&lt;-tryCatch(
      GET(paste0(&quot;https://cran.stat.auckland.ac.nz/src/contrib/Archive/&quot;,pkg,&quot;/&quot;)),
      error=function(e) list(NULL)
  )
}  </code></pre>
<p>Now, extract dates for archived versions</p>
<pre class="r"><code>all_dates&lt;-vector(&quot;list&quot;,length(all_archives))
for(i in seq_len(length(all_archives))){
                 pkg&lt;-all_archives[[i]]
                    if (is.null(pkg)) 
                      all_dates[[i]]&lt;-as.Date(character(0))
                    else{
                      txt&lt;-unlist(as_list(xml_find_all(content(pkg), &quot;//body/table/tr/td&quot;)))[-(1:3)]
                      n&lt;-length(txt)/3
                      all_dates[[i]]&lt;-as.Date(txt[(1:n)*3-1], format=&quot;%d-%b-%Y&quot;)
                  }
}
arch_dates&lt;-data.frame(pkg=archived_names, first=sapply(all_dates,min),latest=sapply(all_dates,max))</code></pre>
<p>Get the current package dates from CRAN again (because <code>available.packages()</code> doesn’t give them)</p>
<pre class="r"><code>cran_table&lt;-GET(&quot;https://cran.r-project.org/web/packages/available_packages_by_date.html&quot;)
cran_list&lt;-as_list(xml_find_all(content(cran_table,&quot;parsed&quot;),&quot;//body/table/tr&quot;))[-1]
cran_dates&lt;-data.frame(pkg=sapply(cran_list, function(x) x[[3]]$a[[1]]),
                       date=sapply(cran_list, function(x) as.Date(x[[1]][[1]]))) </code></pre>
<p>Now combine the two sets of dates</p>
<pre class="r"><code>all_dates&lt;-merge(cran_dates,arch_dates,by=&quot;pkg&quot;,all=TRUE)
all_dates$current&lt;-with(all_dates, ifelse(is.na(date),latest,date))
all_dates$enter&lt;-with(all_dates, ifelse(is.na(first),date,first))</code></pre>
<p>What counts as ‘now’ for the survival analysis? The last time packages were dropped from CRAN is too early; the last time they were added is too late; these only differ by three weeks, so we won’t worry too much. We need to add 1 because packages can only be dropped after they are actually added. In fact, we should add more than 1 for recent packages, because it’s going to take a few weeks at least to drop a new package. But it’s not worth worrying more given the time scales we’re working with.</p>
<pre class="r"><code>all_dates$now&lt;-max(all_dates$date,na.rm=TRUE)+1
all_dates$dropped&lt;-is.na(all_dates$date)
all_dates$stop&lt;-with(all_dates, ifelse(dropped, current, now))</code></pre>
<p>Here’s the overall survival curve for packages on CRAN: there’s an initial drop-off of a few percent, but most packages last a long time.</p>
<pre class="r"><code>library(survival)
pkg_srv&lt;- survfit(Surv(stop-enter,dropped)~1,data=all_dates)
plot(pkg_srv)</code></pre>
<p><img src="/post/2018-12-17-what-are-packages-for_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Now, this might have changed over the years Perhaps in the Good Old Days we made packages to last for ever, but kids these days write packages that are flaky and liable to vanish at any moment?</p>
<pre class="r"><code>library(survival)
library(ggplot2)
library(ggfortify)
all_dates$years&lt;-cut(all_dates$enter%/%365+1971,c(0,1997+4*(1:5), Inf))
pkg_srv&lt;- survfit(Surv(stop-enter,dropped)~years,data=all_dates)
autoplot(pkg_srv,facet=TRUE,ncol=2,scales=&quot;fixed&quot;)</code></pre>
<p><img src="/post/2018-12-17-what-are-packages-for_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>It’s actually the other way around. In the early days there were more short-lived packages: the language and the community were changing more rapidly, so this makes sense.</p>
<p>We get the same picture from Cox models</p>
<pre class="r"><code>coxph(Surv(stop-enter,dropped)~years,data=all_dates)</code></pre>
<pre><code>## Call:
## coxph(formula = Surv(stop - enter, dropped) ~ years, data = all_dates)
## 
##                    coef exp(coef) se(coef)     z       p
## years(2001,2005] -0.235     0.790    0.188 -1.25    0.21
## years(2005,2009] -0.157     0.855    0.171 -0.92    0.36
## years(2009,2013] -0.266     0.767    0.168 -1.59    0.11
## years(2013,2017] -1.092     0.335    0.170 -6.44 1.2e-10
## years(2017,Inf]  -1.847     0.158    0.189 -9.80 &lt; 2e-16
## 
## Likelihood ratio test=506  on 5 df, p=0
## n= 15433, number of events= 1898</code></pre>
<p>Over all, the two decades of CRAN aren’t long enough to tell us what the median survival time is for packages. Or even the first quartile. But, to the extent that there’s a trend, CRAN packages written in recent years are less likely to disappear than those written in the past were (at the same age).</p>
</div>
<div id="and-finally" class="section level3">
<h3>And, finally</h3>
<p>The suggestion that people are ‘wasting’ time working on statistical computing is going to attract a less calm and more negative response than one might naively expect. That’s because so much academic statistical computing has been described, so often, as a waste of its developers’ time. R itself has certainly not been exempt from this.</p>
</div>
