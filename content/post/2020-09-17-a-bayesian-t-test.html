---
title: A Bayesian t-test?
author: Thomas Lumley
date: '2020-09-17'
slug: a-bayesian-t-test
categories: []
tags: []
---



<blockquote>
<p><em>“How do you know the treatment has the same effect on everyone when you don’t even know whether it makes the outcome go up or down?”</em> –Scott S. Emerson <em>(possibly a paraphrase)</em></p>
</blockquote>
<p>What’s the Bayesian equivalent of a basic two-sample <span class="math inline">\(t\)</span>-test? This looks like an easy question: <span class="math inline">\(X_i\sim N(\mu_x,\sigma^2)\)</span>, <span class="math inline">\(Y_i\sim N(\mu_y,\sigma^2)\)</span>, independent flat priors on <span class="math inline">\(\mu_x\)</span> and <span class="math inline">\(\mu_y\)</span> and some sort of reference prior on <span class="math inline">\(\sigma^2\)</span>. Back 100 years ago that would have been a good answer (over and above being a revolutionary question). But we don’t teach the <span class="math inline">\(t\)</span>-test as being about location shift in Normal distributions any more.</p>
<p>The <span class="math inline">\(t\)</span>-test, now, is the test comparing <span class="math inline">\(\bar X\)</span> to <span class="math inline">\(\bar Y\)</span> using the Normal approximation to their distributions provided by the Central Limit Theorem. You might, later, explain that the small-sample behaviour is especially good in the case where <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have Normal distributions, and that the small-sample behaviour can be improved further if you know in advance that the variance is the same in both groups, but that’s not the primary use case. In particular, the location-shift (equal variance) assumption is unnecessary and rarely well-motivated, and leads to poorly-calibrated inference if violated (even in large samples).</p>
<p>Now, it’s probably true that the operating characteristics of the Bayesian analysis are pretty robust to the model specification given a reasonable sample size, just as they are for the <span class="math inline">\(t\)</span>-test. But one of the common selling points of Bayesian statistics in introductory courses is that you don’t need to do that sort of asymptotic approximation; that the posterior distribution is right <strong>because it’s right</strong>. If you’re arguing “no ad-hockery” you are estopped from also arguing “convenience priors and asymptotics”. And even if you’re not doing that, have you actually checked the robustness of the Bayesian inference in the appropriate ways, or found a reference that has? No, I thought not.</p>
<p>Can we come up with a straightforward Bayesian comparison of means that doesn’t assume a Normal distribution and a location shift? The latter (counter-intuitively) may be the stronger assumption, at least in large samples, since assuming the two distributions differ only by location lets you construct an adaptive rank test that is as powerful as if you also knew the what the common distribution was.</p>
<p>We can start with discrete distributions. Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> each take only a finite set of values. We can model these as multinomial distributions on <span class="math inline">\(1,\dots,M_x\)</span> and <span class="math inline">\(1,\dots,M_y\)</span>, with weights <span class="math inline">\(w_{x1},\dots w_{xM_x}\)</span> and <span class="math inline">\(w_{y1},\dots w_{yM_y}\)</span>. Note that we don’t assume that the values, or even the number of values, is the same. <span class="math inline">\(X\)</span> could be ticket prices for a Test at Eden Park, and <span class="math inline">\(Y\)</span> ticket prices for a concert at Spark Arena. We can reasonably put Dirichlet<span class="math inline">\((\alpha)\)</span> priors on the vectors of probabilities <span class="math inline">\(p_{xm}\)</span> and <span class="math inline">\(p_{ym}\)</span> and I will assume the <span class="math inline">\(w\)</span>s are known constants.</p>
<p>Given the posterior probabilities, we can compute posterior means <span class="math inline">\(\mu_x=\sum_m p_{xm}w_{xm}\)</span> and <span class="math inline">\(\mu_y=\sum_m p_{ym}w_{ym}\)</span>. These will have an exact distribution that we can sample from, and they will also be approximately Normal for large sample sizes<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> in a well-understood way because they are sums of the <span class="math inline">\(w_m\)</span>.</p>
<p>Even better, the posterior distribution is given by a bootstrap that’s slightly smoothed by the prior and the Normal approximation is a smoothed version of what you’d as estimates and confidence intervals for the unequal-variance <span class="math inline">\(t\)</span>-test – in both cases you simply replace the empirical frequencies with the posterior probabilities. Write <span class="math inline">\(n_{xm}\)</span> for the observed counts and <span class="math inline">\(\hat p_{xm}=n_{xm}/\sum_m n_{xm}\)</span> for the empirical proportions. The bootstrap resamples <span class="math inline">\(X_m\)</span> with probability <span class="math inline">\(\hat p_{xm}\)</span>; the posterior distribution uses
<span class="math display">\[p_{x_m}=\frac{n_{xm}+\alpha_{xm}}{\sum_m n_{xm} +\alpha_{xm}}.\]</span>
The empirical difference in means is
<span class="math inline">\(\sum_m \hat p_{xm}w_{xm} - \sum_m \hat p_{ym}w_{ym}\)</span>
and the posterior mean difference is
<span class="math inline">\(\sum_m p_{xm}w_{xm} - \sum_m p_{ym}w_{ym}.\)</span>
Similarly, the formulas for the standard error of the mean and the posterior standard deviation differ only by the smoothing using <span class="math inline">\(\alpha\)</span> (and perhaps a degrees-of-freedom correction), as do the formulas for the standard error of the difference in means and the posterior standard deviation of the difference in means. That is, they fit the case for Bayesian estimators as sensibly regularised versions of classical estimators.</p>
<p>A hypothesis test is a bit trickier, but (a) you probably don’t care, and (b) if you do, you could constrain <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to have the same prior mean, or to have <span class="math inline">\(\mu_x-\mu_y\)</span> be any specified value. That would let you compute a Bayes factor comparing <span class="math inline">\(\mu_x-\mu_y=0\)</span> to some other prior distribution over <span class="math inline">\(\mu_x-\mu_y\)</span>. You could even work out the posterior distributions for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> constraining their posterior means to be the same, using <a href="https://projecteuclid.org/euclid.ba/1362406653">these ideas</a> from Charlie Geyer and Glen Meeden, though we’re getting less elementary there.</p>
<p>How do you get beyond discrete data? Well, you can pretend it’s discrete, as Rubin does in the “Bayesian Bootstrap” paper, and have a multinomial/Dirichlet distribution over the values that are actually observed. Or, in a more modern approach, you could use a Dirichlet process prior for each variable, which still gives the resampling-like exact Bayesian inference and <span class="math inline">\(t\)</span>-test-like approximate (Bayesian or classical) inference.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>note that we don’t need the number of observations in each category to be large, just the total number of observations, together with some bounds on the extremes of the <span class="math inline">\(w_m\)</span><a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
