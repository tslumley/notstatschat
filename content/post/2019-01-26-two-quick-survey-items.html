---
title: Two quick survey items
author: Thomas Lumley
date: '2019-01-26'
slug: two-quick-survey-items
categories: []
tags: []
---



<div id="can-we-invent-the-case-control-design" class="section level1">
<h1>Can we invent the case-control design?</h1>
<p>Classical survey analysis is about means and totals, and the way to adapt it to more interesting parameters is to write the parameter as the mean of its influence functions (delta-betas, jackknife values, etc)</p>
<p>Suppose we knew for everyone in a population (maybe an HMO) whether they had a disease (<span class="math inline">\(Y=1\)</span> or didn’t (<span class="math inline">\(Y=0\)</span>) and we wanted to take a sample, measure a variable <span class="math inline">\(X\)</span>, and do logistic regression. What sampling probabilities should we use?</p>
<p>The optimal stratified sampling design for estimating a total is `Neyman allocation’, where the number of people we sample in each stratum is proportional to the size of the stratum in the population and to the standard deviation of the variable.</p>
<p>In our case the variable is the influence function for a logistic regression coefficient <span class="math inline">\(\beta\)</span>, which is proportional to the score function, which is <span class="math display">\[U_i=X_i(Y_i-p_i)\]</span> where <span class="math inline">\(p_i\)</span> is the fitted probability for person <span class="math inline">\(i\)</span>.</p>
<p>Let’s assume we have a rare disease (<span class="math inline">\(E[Y]=p_0\)</span>) and modest covariate effects, so <span class="math inline">\(p_i\ll 1\)</span> for all <span class="math inline">\(i\)</span>. In the case stratum, <span class="math inline">\(U_i=X_i(1-p_i)\)</span>, so <span class="math display">\[\mathrm{var}[U_i|Y=1]\approx \mathrm{var}[X_i|Y_i=1]\approx \mathrm{var}[X]\]</span> where the last approximate equality is exact if <span class="math inline">\(\beta=0\)</span> or if <span class="math inline">\(X\)</span> is Normal and is pretty good otherwise.</p>
<p>In the control stratum <span class="math inline">\(U_i=-X_ip_i\)</span>, so <span class="math display">\[\mathrm{var}[U_i|Y=0]\approx p_0^2\mathrm{var}[X].\]</span> This approximation isn’t as good as the case one, since <span class="math inline">\(p_i\)</span> could vary quite a bit while <span class="math inline">\(1-p_i\)</span> stays roughly constant: typically the control variance will be a bit bigger.</p>
<p>Neyman allocation says we need to take the population stratum sizes <span class="math inline">\(N_h\)</span> and the population stratum standard deviations <span class="math inline">\(S_h\)</span> and compute <span class="math inline">\(N_hS_h\)</span> for each stratum <span class="math inline">\(h\)</span>. Under our approximations, these come to <span class="math inline">\(Np_0\sqrt{\mathrm{var[X]}}\)</span> for cases and <span class="math inline">\(N(1-p_0)\sqrt{p_0^2\mathrm{var}[X]}\)</span> for controls, which are about equal. We should take the same number of cases and controls when covariate effects are small; we should probably take a few more cases when covariate effects are large.</p>
<p>Note that this is for the design-weighted logistic regression estimator, but it’s pretty insenstive to how efficient this weighted estimator is (which ranges from fully efficient to horribly inefficient depending on <span class="math inline">\(\beta\)</span> and the distribution of <span class="math inline">\(X\)</span>.)</p>
</div>
<div id="variances-in-two-phase-designs" class="section level1">
<h1>Variances in two-phase designs</h1>
<p>This is an explanation of the internals of <code>twophase2.R</code> in the survey package.</p>
<p>In a two-phase sample you take a sample, then take a sample from it. Two-phase sampling generalises two-stage sampling in that the sampling probabilities for the second phase are allowed to depend on data observed at the first phase.</p>
<p>The sampling weight <span class="math inline">\(\pi^*_i\)</span> for unit <span class="math inline">\(i\)</span> is the product of the probability of sampling unit <span class="math inline">\(i\)</span> at phase one (<span class="math inline">\(\pi_i1\)</span>) multiplied by the probability of sampling unit <span class="math inline">\(i\)</span> at phase two, conditional on the whole phase-one sample we took (<span class="math inline">\(\pi_{i,2|1}\)</span>). This is <strong>not</strong> the marginal probability of sampling unit <span class="math inline">\(i\)</span>, as in the Horvitz-Thompson estimator. The marginal probability <span class="math inline">\(\pi_i\)</span> would be the average of <span class="math inline">\(\pi_i^*\)</span> over all phase-1 samples that include unit <span class="math inline">\(i\)</span>, which in your case you have not got. Fortunately, you can use <span class="math inline">\(\pi_i^*\)</span> just like you’d use <span class="math inline">\(\pi_i\)</span>. (An interesting question: if you did have <span class="math inline">\(\pi_i\)</span> would it be better or worse to use it instead?)</p>
<p>In particular, we can use the same form of variance estimator as for the Horvitz-Thompson estimator, which has the deceptively compact form <span class="math display">\[\widehat{\mathrm{var}}[{\hat T}_X]= \sum_{i,j}\check{\Delta}_{ij}\check{X}_i\check{X}_j.\]</span> Here, <span class="math inline">\(\Delta_{ij}\)</span> is the covariance of the sampling indicators for units <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, and the hacek/caron accent indicates weighting. That is <span class="math inline">\(\check{X}_i=X_i/\pi^*_i\)</span> and <span class="math display">\[\check{\Delta}_{ij}=\Delta_{ij}/\pi_{ij}^*\]</span> where <span class="math inline">\(\pi^*_{ij}\)</span> is the pairwise inclusion version of <span class="math inline">\(\pi_i^*\)</span>. Strictly speaking, it’s <span class="math inline">\({\Delta}^*=\pi_{ij}^*-\pi_i^*\pi_j^*\)</span> but that’s too many stars to bother writing.</p>
<p>The advantage of this form is that <span class="math inline">\(\check{\Delta}\)</span> composes nicely over stages and phases of sampling. If you have one stage or phase of sampling with <span class="math inline">\(\check{\Delta}_1\)</span> and another with <span class="math inline">\(\check{\Delta}_2\)</span>, the overall weighted covariance is <span class="math display">\[\check{\Delta}=\check{\Delta}_1+\check{\Delta}_2-\check{\Delta}_1\cdot\check{\Delta}_2.\]</span> <em>(The <span class="math inline">\(\cdot\)</span> means this is the element-wise (Hadamard) product, not the matrix product.)</em></p>
<p>We still need to know what <span class="math inline">\(\check{\Delta}_{ij}\)</span> is. If we have simple random sampling (potentially of clusters, within strata) of <span class="math inline">\(n\)</span> units out of <span class="math inline">\(N\)</span>, then <span class="math display">\[\check{\Delta}= -(1-n/N)/(n-1)=-(1-\pi_i)/(n-1).\]</span> The last form is especially useful, because when we’re working with a particular stage of sampling we’re going to have the probabilities at that stage and the sample size at that stage conveniently available, but we might not have <span class="math inline">\(N\)</span> and <span class="math inline">\(\pi_{ij}\)</span> conveniently available.</p>
</div>
